{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Содержание<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Подготовка-данных\" data-toc-modified-id=\"Подготовка-данных-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Подготовка данных</a></span><ul class=\"toc-item\"><li><span><a href=\"#Вывод\" data-toc-modified-id=\"Вывод-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Вывод</a></span></li></ul></li><li><span><a href=\"#Исследование-задачи\" data-toc-modified-id=\"Исследование-задачи-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Исследование задачи</a></span><ul class=\"toc-item\"><li><span><a href=\"#Вывод\" data-toc-modified-id=\"Вывод-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Вывод</a></span></li></ul></li><li><span><a href=\"#Борьба-с-дисбалансом\" data-toc-modified-id=\"Борьба-с-дисбалансом-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Борьба с дисбалансом</a></span><ul class=\"toc-item\"><li><span><a href=\"#Upsampling\" data-toc-modified-id=\"Upsampling-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Upsampling</a></span></li><li><span><a href=\"#Вывод\" data-toc-modified-id=\"Вывод-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Вывод</a></span></li><li><span><a href=\"#Downsampling\" data-toc-modified-id=\"Downsampling-3.3\"><span class=\"toc-item-num\">3.3&nbsp;&nbsp;</span>Downsampling</a></span></li><li><span><a href=\"#Вывод\" data-toc-modified-id=\"Вывод-3.4\"><span class=\"toc-item-num\">3.4&nbsp;&nbsp;</span>Вывод</a></span></li><li><span><a href=\"#Взвешивание-классов\" data-toc-modified-id=\"Взвешивание-классов-3.5\"><span class=\"toc-item-num\">3.5&nbsp;&nbsp;</span>Взвешивание классов</a></span></li><li><span><a href=\"#Вывод\" data-toc-modified-id=\"Вывод-3.6\"><span class=\"toc-item-num\">3.6&nbsp;&nbsp;</span>Вывод</a></span></li></ul></li><li><span><a href=\"#Тестирование-модели\" data-toc-modified-id=\"Тестирование-модели-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Тестирование модели</a></span></li><li><span><a href=\"#Общий-вывод\" data-toc-modified-id=\"Общий-вывод-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Общий вывод</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Отток клиентов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Из банка стали уходить клиенты. Банковские маркетологи посчитали: сохранять текущих клиентов дешевле, чем привлекать новых.\n",
    "\n",
    "В этом проекте спрогнозируем, уйдёт клиент из банка в ближайшее время или нет, так как эта информация поможет маркетологам составить стратегию для сохранения текущих клиентов.  \n",
    "\n",
    "Для исследования предоставлены исторические данные о поведении 10000 клиентов и расторжении договоров с банком. А именно данные: о регионе проживания, поле, возрасте, наличии кредитной карты, сколько лет человек является клиеном банка, балансе на счете, кредитном рейтинге, количестве исчпользуемых продуктов банка, количестве продуктов банка, используемых клиентом, активности и предполагаемой заработной плате. На основании этих данных будет составлена модель для прогнозирования ухода клиента из банка. \n",
    "\n",
    "План работы:\n",
    "- Загрузить и подготовить данные.\n",
    "- Исследовать баланс классов, обучить модель без учёта дисбаланса, сделать выводы.\n",
    "- Улучшить качество модели, учитывая дисбаланс классов. Обучить разные модели и найти лучшую, сделать выводы.\n",
    "- Провести финальное тестирование.\n",
    "\n",
    "Источник данных: [https://www.kaggle.com/barelydedicated/bank-customer-churn-modeling](https://www.kaggle.com/barelydedicated/bank-customer-churn-modeling)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подготовка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    data = pd.read_csv('/datasets/Churn.csv')\n",
    "except:\n",
    "    data = pd.read_csv('datasets/Churn.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 14 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   RowNumber        10000 non-null  int64  \n",
      " 1   CustomerId       10000 non-null  int64  \n",
      " 2   Surname          10000 non-null  object \n",
      " 3   CreditScore      10000 non-null  int64  \n",
      " 4   Geography        10000 non-null  object \n",
      " 5   Gender           10000 non-null  object \n",
      " 6   Age              10000 non-null  int64  \n",
      " 7   Tenure           9091 non-null   float64\n",
      " 8   Balance          10000 non-null  float64\n",
      " 9   NumOfProducts    10000 non-null  int64  \n",
      " 10  HasCrCard        10000 non-null  int64  \n",
      " 11  IsActiveMember   10000 non-null  int64  \n",
      " 12  EstimatedSalary  10000 non-null  float64\n",
      " 13  Exited           10000 non-null  int64  \n",
      "dtypes: float64(3), int64(8), object(3)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создали датафрейм, изучили общую информацию. В датасете содержатся столбцы:\n",
    "\n",
    "Признаки\n",
    "- RowNumber — индекс строки в данных\n",
    "- CustomerId — уникальный идентификатор клиента\n",
    "- Surname — фамилия\n",
    "- CreditScore — кредитный рейтинг\n",
    "- Geography — страна проживания\n",
    "- Gender — пол\n",
    "- Age — возраст\n",
    "- Tenure — сколько лет человек является клиентом банка\n",
    "- Balance — баланс на счёте\n",
    "- NumOfProducts — количество продуктов банка, используемых клиентом\n",
    "- HasCrCard — наличие кредитной карты\n",
    "- IsActiveMember — активность клиента\n",
    "- EstimatedSalary — предполагаемая зарплата\n",
    "\n",
    "Целевой признак\n",
    "- Exited — факт ухода клиента"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Целевой признак - категориальный, так как факт ухода клиента может иметь только два значения (клиент ушел или не ушел), значит решается задача бинарной классификации."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Названия столбцов не соответствуют стандартам, изменим их в соответствии со стандартами."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\oyuki\\AppData\\Local\\Temp\\ipykernel_17168\\3846741158.py:1: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  data.columns = data.columns.str.replace(r\"([A-Z])\", r\" \\1\").str.lower().str.replace(' ', '_').str[1:]\n"
     ]
    }
   ],
   "source": [
    "data.columns = data.columns.str.replace(r\"([A-Z])\", r\" \\1\").str.lower().str.replace(' ', '_').str[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['row_number', 'customer_id', 'surname', 'credit_score', 'geography',\n",
       "       'gender', 'age', 'tenure', 'balance', 'num_of_products', 'has_cr_card',\n",
       "       'is_active_member', 'estimated_salary', 'exited'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь столбцы имеют названия, соответствующие стандартам.\n",
    "\n",
    "Также в данных есть пропуски (признак tenure), это мешает работе с датасетом, необходимо их заполнить."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.,  1.,  8.,  7.,  4.,  6.,  3., 10.,  5.,  9.,  0., nan])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['tenure'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Количество лет, в течение которых клиент пользуется услугами банка, варьируется от 0 до 10.\n",
    "\n",
    "Заполним пропуски специальным значением -1, после чего изменим тип данных столбца на 'object'. Таким образом получим категориальный признак, так как значений в этом признаке ограниченное количество"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['tenure'] = data['tenure'].fillna(-1)\n",
    "data['tenure'] = data['tenure'].astype('object')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Также удалим из датафрейма столбцы surname, row_number, customer_id, так как фамилия клиента и индексы никак не влияют на целевой признак и могут только запутать модель."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "useless = ['surname', 'row_number', 'customer_id']\n",
    "data = data.drop(useless, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Также в данных есть категориальные признаки, это помешает обучению моделей. Преобразуем эти признаки в численные с помощью прямого кодирования OHE (One-Hot Encoding)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ohe = pd.get_dummies(data, drop_first=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Далее нужно разделить датасет на признаки и целевой признак, а также на обучающую (60%), валидационную (20%) и тестовую (20%) выборки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = data_ohe.drop('exited', axis=1)\n",
    "target = data_ohe['exited']\n",
    "\n",
    "features_train, features_valid_and_test, target_train, target_valid_and_test = train_test_split(features, target, \n",
    "                                                                                                test_size=0.4, \n",
    "                                                                                                random_state=12345)\n",
    "\n",
    "features_valid, features_test, target_valid, target_test = train_test_split(features_valid_and_test, target_valid_and_test,\n",
    "                                                                           test_size=0.5, random_state=12345)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Удостоверимся, что данные поделены верно."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6000, 21)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 21)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 21)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6000,)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000,)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000,)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь данные разделены на три выборки: обучающая, валидационная и тестовая.\n",
    "\n",
    "В данных могут быть количественные признаки с разными разбросами значений. Чтобы алгоритм обучения не решил, что какой-то признак важнее другого, нужно масштабировать данные, сделаем это с помощью стандартизации данных.\n",
    "\n",
    "Выделим столбцы с количественными признаками."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric = ['credit_score', 'age', 'balance', 'num_of_products', 'estimated_salary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(features_train[numeric])\n",
    "\n",
    "features_train[numeric] = scaler.transform(features_train[numeric])\n",
    "features_valid[numeric] = scaler.transform(features_valid[numeric])\n",
    "features_test[numeric] = scaler.transform(features_test[numeric])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 22 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   credit_score       10000 non-null  int64  \n",
      " 1   age                10000 non-null  int64  \n",
      " 2   balance            10000 non-null  float64\n",
      " 3   num_of_products    10000 non-null  int64  \n",
      " 4   has_cr_card        10000 non-null  int64  \n",
      " 5   is_active_member   10000 non-null  int64  \n",
      " 6   estimated_salary   10000 non-null  float64\n",
      " 7   exited             10000 non-null  int64  \n",
      " 8   geography_Germany  10000 non-null  uint8  \n",
      " 9   geography_Spain    10000 non-null  uint8  \n",
      " 10  gender_Male        10000 non-null  uint8  \n",
      " 11  tenure_0.0         10000 non-null  uint8  \n",
      " 12  tenure_1.0         10000 non-null  uint8  \n",
      " 13  tenure_2.0         10000 non-null  uint8  \n",
      " 14  tenure_3.0         10000 non-null  uint8  \n",
      " 15  tenure_4.0         10000 non-null  uint8  \n",
      " 16  tenure_5.0         10000 non-null  uint8  \n",
      " 17  tenure_6.0         10000 non-null  uint8  \n",
      " 18  tenure_7.0         10000 non-null  uint8  \n",
      " 19  tenure_8.0         10000 non-null  uint8  \n",
      " 20  tenure_9.0         10000 non-null  uint8  \n",
      " 21  tenure_10.0        10000 non-null  uint8  \n",
      "dtypes: float64(2), int64(6), uint8(14)\n",
      "memory usage: 761.8 KB\n"
     ]
    }
   ],
   "source": [
    "data_ohe.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вывод"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Итак, данные подготовлены к работе. Что было сделано:\n",
    "\n",
    "1. Сначала был создан датафрейм, изучен.\n",
    "2. Обработаны пропуски в столбце *tenure*, заполнены медианным значением.\n",
    "3. Удален столбце *surname*, так как он не нужен для решения поставленной задачи.\n",
    "4. Категориальные признаки превращены в численные с помощью прямого кодирования OHE.\n",
    "5. Датасет разделен на обучающую, валидационную и тестовую выборки.\n",
    "6. Столбцы с количественными признаками масштабированы, чтобы избежать того, что модель выделит какие-то признаки как более важные."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Исследование задачи"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим, есть ли дисбаланс классов в данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    7963\n",
       "1    2037\n",
       "Name: exited, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['exited'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Дисбаланс определенно есть, соотношение далеко от 1:1. В данном случае около 80% и 20%.\n",
    "\n",
    "Сначала обучим и исследуем модели без учета дисбаланса классов.\n",
    "\n",
    "Начнем с модели случайного леса, подберем параметры с помощью GridSearch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_forest = { 'n_estimators': range (1, 81, 10),\n",
    "                     'max_depth': range (2,15,2),\n",
    "                     'min_samples_leaf': range (2,11,2),\n",
    "                     'min_samples_split': range (2,11,2) }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_tree = { 'max_depth': range (2,15,2),\n",
    "                   'min_samples_leaf': range (2,11,2),\n",
    "                   'min_samples_split': range (2,11,2) }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 49.5 s\n",
      "Wall time: 7min 20s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'max_depth': 14,\n",
       " 'min_samples_leaf': 2,\n",
       " 'min_samples_split': 8,\n",
       " 'n_estimators': 31}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "rfc_unbalanced = RandomForestClassifier(random_state=12345)\n",
    "\n",
    "rfc_gs_unbalanced = GridSearchCV(estimator = rfc_unbalanced, param_grid = parameters_forest, cv=5, scoring='f1', n_jobs = -1)\n",
    "rfc_gs_unbalanced.fit(features_train, target_train)\n",
    "rfc_gs_unbalanced.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 мера лучшей модели случайного леса: 0.5557299843014128\n",
      "AUC-ROC метрика: 0.8503348072514351\n"
     ]
    }
   ],
   "source": [
    "rfc_unbalanced = rfc_gs_unbalanced.best_estimator_\n",
    "rfc_unbalanced.fit(features_train, target_train)\n",
    "\n",
    "predictions_valid = rfc_unbalanced.predict(features_valid)\n",
    "predicted_proba_valid = rfc_unbalanced.predict_proba(features_valid)\n",
    "predictions_one_valid = predicted_proba_valid[:, 1]\n",
    "\n",
    "print('F1 мера лучшей модели случайного леса:', f1_score(target_valid, predictions_valid))\n",
    "print('AUC-ROC метрика:', roc_auc_score(target_valid, predictions_one_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Итак, получили результат f1 0.56, не очень высокий, но это предварительная модель и предварительная оценка. Метрика качества AUC-ROC же 0.843, что является неплохим результатом (значительно больше чем 0.5 у случайной модели).\n",
    "\n",
    "Изучим модель решающего дерева, подберем параметры."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 2.77 s\n",
      "Wall time: 8.54 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'max_depth': 12, 'min_samples_leaf': 10, 'min_samples_split': 2}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "dtc_unbalanced = DecisionTreeClassifier(random_state=12345)\n",
    "\n",
    "dtc_gs_unbalanced = GridSearchCV(estimator = dtc_unbalanced, param_grid = parameters_tree, cv=5, scoring='f1', n_jobs = -1)\n",
    "dtc_gs_unbalanced.fit(features_train, target_train)\n",
    "dtc_gs_unbalanced.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 мера лучшей модели решающего дерева: 0.559774964838256\n",
      "AUC-ROC метрика: 0.7827276356619626\n"
     ]
    }
   ],
   "source": [
    "dtc_unbalanced = dtc_gs_unbalanced.best_estimator_\n",
    "dtc_unbalanced.fit(features_train, target_train)\n",
    "\n",
    "\n",
    "predictions_valid = dtc_unbalanced.predict(features_valid)\n",
    "predicted_proba_valid = dtc_unbalanced.predict_proba(features_valid)\n",
    "predictions_one_valid = predicted_proba_valid[:, 1]\n",
    "\n",
    "print('F1 мера лучшей модели решающего дерева:', f1_score(target_valid, predictions_valid))\n",
    "print('AUC-ROC метрика:', roc_auc_score(target_valid, predictions_one_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Результат для дерева решений - 0.546, еще меньше, чем у случайного леса. Но метрика AUC-ROC также неплоха - 0.82.\n",
    "\n",
    "Рассмотрим теперь логистическую регрессию."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(penalty='l1', random_state=12345, solver='liblinear')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_lr_unbalanced = LogisticRegression(random_state=12345, solver='liblinear', penalty='l1')\n",
    "model_lr_unbalanced.fit(features_train, target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 мера лучшей модели логистической регрессии: 0.32830820770519265\n",
      "AUC-ROC метрика: 0.759809822222491\n"
     ]
    }
   ],
   "source": [
    "predictions_valid = model_lr_unbalanced.predict(features_valid)\n",
    "predicted_proba_valid = model_lr_unbalanced.predict_proba(features_valid)\n",
    "predictions_one_valid = predicted_proba_valid[:, 1]\n",
    "\n",
    "print('F1 мера лучшей модели логистической регрессии:', f1_score(target_valid, predictions_valid))\n",
    "print('AUC-ROC метрика:', roc_auc_score(target_valid, predictions_one_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Результаты модели логистической регрессии самые низкие. Этот алгоритм ищет взаимосвязи между признаками и целевым признаком. Возможно, в данном случае эти связи не такие прямые и очевидные, поэтому логистическая регрессия показывает не очень хорошие результаты. Также сказывается дисбаланс классов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вывод"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "По итогам исследования результаты меры F1 у трех моделей получились не очень высокими:\n",
    "- случайный лес 0.555\n",
    "- дерево решений 0.559\n",
    "- логистическая регрессия 0.328\n",
    "\n",
    "Метрика AUC-ROC:\n",
    "- случайный лес 0.85\n",
    "- дерево решений 0.782\n",
    "- логистическая регрессия 0.76\n",
    "\n",
    "Для подбора лучших параметров использовался алгоритм GridSearch. Получившаяся модель с этими параметрами обучалась и давала предсказания, которые сравнивались с действительными значениями целевого признака с помощью метрики F1. \n",
    "\n",
    "Очевидно, это вызвано тем, что в данных есть сильный дисбаланс классов (80% : 20%). По умолчанию все классы имеют один вес, а так как классы в этом датасете в не ровном соотношении, то без корректировки это приводит к дисбалансу и неправильному обучению."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Борьба с дисбалансом"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upsampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Стоит разобраться с дисбалансов классов. Для этого можно использовать метод upsampling, который копирует данные с меньшим классом несколько раз. В данном случае умножим выборку в 4 раза, чтобы классы стали равнозначны."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upsample(features, target, repeat):\n",
    "    features_zeros = features[target == 0]\n",
    "    features_ones = features[target == 1]\n",
    "    target_zeros = target[target == 0]\n",
    "    target_ones = target[target == 1]\n",
    "    features_upsampled = pd.concat([features_zeros] + [features_ones] * repeat)\n",
    "    target_upsampled = pd.concat([target_zeros] + [target_ones] * repeat)\n",
    "    features_upsampled, target_upsampled = shuffle(\n",
    "    features_upsampled, target_upsampled, random_state=12345)\n",
    "\n",
    "    return features_upsampled, target_upsampled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Размеры классов до преобразования:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4804\n",
       "1    1196\n",
       "Name: exited, dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train_up, target_train_up = upsample(features_train, target_train, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Размеры классов после преобразования:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4804\n",
       "1    4784\n",
       "Name: exited, dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_train_up.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Итак, разобрались с дисбалансом классов, получилось соотношение примерно 1:1. Теперь можно обучать модели на новой обучающей выборке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 52.4 s\n",
      "Wall time: 9min 46s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'max_depth': 14,\n",
       " 'min_samples_leaf': 2,\n",
       " 'min_samples_split': 2,\n",
       " 'n_estimators': 71}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "rfc_up = RandomForestClassifier(random_state=12345)\n",
    "\n",
    "rfc_gs_up = GridSearchCV(estimator = rfc_up, param_grid = parameters_forest, cv=5, scoring='f1', n_jobs = -1)\n",
    "rfc_gs_up.fit(features_train_up, target_train_up)\n",
    "rfc_gs_up.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 мера лучшей модели случайного леса: 0.6245772266065388\n",
      "AUC-ROC метрика: 0.851828888391534\n"
     ]
    }
   ],
   "source": [
    "rfc_up = rfc_gs_up.best_estimator_\n",
    "rfc_up.fit(features_train_up, target_train_up)\n",
    "\n",
    "predictions_valid = rfc_up.predict(features_valid)\n",
    "predicted_proba_valid = rfc_up.predict_proba(features_valid)\n",
    "predictions_one_valid = predicted_proba_valid[:, 1]\n",
    "\n",
    "print('F1 мера лучшей модели случайного леса:', f1_score(target_valid, predictions_valid))\n",
    "print('AUC-ROC метрика:', roc_auc_score(target_valid, predictions_one_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 4.23 s\n",
      "Wall time: 11.8 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'max_depth': 14, 'min_samples_leaf': 2, 'min_samples_split': 2}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "dtc_up = DecisionTreeClassifier(random_state=12345)\n",
    "\n",
    "dtc_gs_up = GridSearchCV(estimator = dtc_up, param_grid = parameters_tree, cv=5, scoring='f1', n_jobs = -1)\n",
    "\n",
    "dtc_gs_up.fit(features_train_up, target_train_up)\n",
    "\n",
    "dtc_gs_up.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 мера лучшей модели решающего дерева: 0.5063829787234042\n",
      "AUC-ROC метрика: 0.7128611956278467\n"
     ]
    }
   ],
   "source": [
    "dtc_up = dtc_gs_up.best_estimator_\n",
    "dtc_up.fit(features_train_up, target_train_up)\n",
    "\n",
    "predictions_valid = dtc_up.predict(features_valid)\n",
    "predicted_proba_valid = dtc_up.predict_proba(features_valid)\n",
    "predictions_one_valid = predicted_proba_valid[:, 1]\n",
    "\n",
    "print('F1 мера лучшей модели решающего дерева:', f1_score(target_valid, predictions_valid))\n",
    "print('AUC-ROC метрика:', roc_auc_score(target_valid, predictions_one_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(penalty='l1', random_state=12345, solver='liblinear')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_lr_up = LogisticRegression(random_state=12345, solver='liblinear', penalty='l1')\n",
    "model_lr_up.fit(features_train_up, target_train_up)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 мера лучшей модели логистической регрессии: 0.48835202761000857\n",
      "AUC-ROC метрика: 0.7643419691626491\n"
     ]
    }
   ],
   "source": [
    "predictions_valid = model_lr_up.predict(features_valid)\n",
    "predicted_proba_valid = model_lr_up.predict_proba(features_valid)\n",
    "predictions_one_valid = predicted_proba_valid[:, 1]\n",
    "\n",
    "print('F1 мера лучшей модели логистической регрессии:', f1_score(target_valid, predictions_valid))\n",
    "print('AUC-ROC метрика:', roc_auc_score(target_valid, predictions_one_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вывод"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Результаты тестов F1 и AUC-ROC определенно выросли для случайного леса и логистической регрессии, так как мы увеличили размер обучающей выборки, а повторение способствует обучению, поэтому качество обучения моделей повысилось. Также мы избавились от дисбаланса классов, что, конечно же, тоже повышает качество обучения. Но вот результаты дерева решений внезапно снизились, возможно, из-за переобучения. Стоит проверить остальные способы решения проблемы дисбаланса и сравнить результаты.\n",
    "\n",
    "Случайный лес:\n",
    "- F1 = 0.624\n",
    "- AUC-ROC = 0.851\n",
    "\n",
    "Решающее дерево:\n",
    "- F1 = 0.506\n",
    "- AUC-ROC = 0.712\n",
    "\n",
    "Логистическая регрессия: \n",
    "- F1 = 0.488\n",
    "- AUC-ROC = 0.764"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downsampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Также для решения проблемы дисбаланса классов есть техника балансирования классов downsampling, которая заключается\n",
    "в уменьшении числа объектов большего класса путём случайного удаления объектов большего класса. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def downsample(features, target, fraction):\n",
    "    features_zeros = features[target == 0]\n",
    "    features_ones = features[target == 1]\n",
    "    target_zeros = target[target == 0]\n",
    "    target_ones = target[target == 1]\n",
    "    features_downsampled = pd.concat(\n",
    "    [features_zeros.sample(frac=fraction, random_state=12345)] + [features_ones])\n",
    "    target_downsampled = pd.concat(\n",
    "    [target_zeros.sample(frac=fraction, random_state=12345)] + [target_ones])\n",
    "    features_downsampled, target_downsampled = shuffle(\n",
    "    features_downsampled, target_downsampled, random_state=12345)\n",
    "    return features_downsampled, target_downsampled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Размеры классов до преобразования:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4804\n",
       "1    1196\n",
       "Name: exited, dtype: int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train_down, target_train_down = downsample(features_train, target_train, 0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Размеры классов до преобразования:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1201\n",
       "1    1196\n",
       "Name: exited, dtype: int64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_train_down.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь соотношение классов в обучающей выборке примерно равно 1:1. Посмотрим, как это повлияет на обучение."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 21.5 s\n",
      "Wall time: 3min 53s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'max_depth': 10,\n",
       " 'min_samples_leaf': 6,\n",
       " 'min_samples_split': 2,\n",
       " 'n_estimators': 51}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "rfc_down = RandomForestClassifier(random_state=12345)\n",
    "\n",
    "rfc_gs_down = GridSearchCV(estimator = rfc_down, param_grid = parameters_forest, cv=5, scoring='f1', n_jobs = -1)\n",
    "rfc_gs_down.fit(features_train_down, target_train_down)\n",
    "rfc_gs_down.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 мера лучшей модели случайного леса: 0.5975494816211122\n",
      "AUC-ROC метрика: 0.85031666051694\n"
     ]
    }
   ],
   "source": [
    "rfc_down = rfc_gs_down.best_estimator_\n",
    "rfc_down.fit(features_train_down, target_train_down)\n",
    "\n",
    "predictions_valid = rfc_down.predict(features_valid)\n",
    "predicted_proba_valid = rfc_down.predict_proba(features_valid)\n",
    "predictions_one_valid = predicted_proba_valid[:, 1]\n",
    "\n",
    "print('F1 мера лучшей модели случайного леса:', f1_score(target_valid, predictions_valid))\n",
    "print('AUC-ROC метрика:', roc_auc_score(target_valid, predictions_one_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 1.22 s\n",
      "Wall time: 3.4 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'max_depth': 6, 'min_samples_leaf': 10, 'min_samples_split': 2}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "dtc_down = DecisionTreeClassifier(random_state=12345)\n",
    "\n",
    "dtc_gs_down = GridSearchCV(estimator = dtc_down, param_grid = parameters_tree, cv=5, scoring='f1', n_jobs = -1)\n",
    "dtc_gs_down.fit(features_train_down, target_train_down)\n",
    "dtc_gs_down.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 мера лучшей модели решающего дерева: 0.5784037558685446\n",
      "AUC-ROC метрика: 0.8306781132235255\n"
     ]
    }
   ],
   "source": [
    "dtc_down = dtc_gs_down.best_estimator_\n",
    "dtc_down.fit(features_train_down, target_train_down)\n",
    "\n",
    "predictions_valid = dtc_down.predict(features_valid)\n",
    "predicted_proba_valid = dtc_down.predict_proba(features_valid)\n",
    "predictions_one_valid = predicted_proba_valid[:, 1]\n",
    "\n",
    "print('F1 мера лучшей модели решающего дерева:', f1_score(target_valid, predictions_valid))\n",
    "print('AUC-ROC метрика:', roc_auc_score(target_valid, predictions_one_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(penalty='l1', random_state=12345, solver='liblinear')"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_lr_down = LogisticRegression(random_state=12345, solver='liblinear', penalty='l1')\n",
    "model_lr_down.fit(features_train_down, target_train_down)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 мера лучшей модели логистической регрессии: 0.48793103448275865\n",
      "AUC-ROC метрика: 0.7631200890399772\n"
     ]
    }
   ],
   "source": [
    "predictions_valid = model_lr_down.predict(features_valid)\n",
    "predicted_proba_valid = model_lr_down.predict_proba(features_valid)\n",
    "predictions_one_valid = predicted_proba_valid[:, 1]\n",
    "\n",
    "print('F1 мера лучшей модели логистической регрессии:', f1_score(target_valid, predictions_valid))\n",
    "print('AUC-ROC метрика:', roc_auc_score(target_valid, predictions_one_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вывод"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Результат для случайного леса получился ниже чем при использовании предыдущего способа. Это объясняется тем, что метод downsampling уменьшает обучающую выборку, что приводит к уменьшению качества обучения в данном случае, так как исследуемый датасет, а следовательно и обучающая выборка, изначально по объему не слишком большие. \n",
    "\n",
    "Но для алгоритма дерева решений заметен значительный прирост качества. Возможно, после использования метода upsampling дерево решений переобучилось, поэтому результаты были ниже. \n",
    "\n",
    "Результаты для логистической регрессии почти не изменились.\n",
    "\n",
    "Случайный лес:\n",
    "- F1 = 0.597\n",
    "- AUC-ROC = 0.85\n",
    "\n",
    "Решающее дерево:\n",
    "- F1 = 0.578\n",
    "- AUC-ROC = 0.830\n",
    "\n",
    "Логистическая регрессия: \n",
    "- F1 = 0.487\n",
    "- AUC-ROC = 0.763"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Взвешивание классов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Используем третий способ решения проблемы дисбаланса классов, а именно корректировка весов классов путем изменения гиперпараметра *class_weight = 'balanced'*. Этот способ изменит веса классов так, чтобы меньший класс имел больший вес (во столько раз больше, во сколько больший класс превосходит меньший)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 28.9 s\n",
      "Wall time: 5min 39s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'max_depth': 10,\n",
       " 'min_samples_leaf': 2,\n",
       " 'min_samples_split': 6,\n",
       " 'n_estimators': 71}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "rfc_w = RandomForestClassifier(random_state=12345, class_weight='balanced')\n",
    "\n",
    "rfc_gs_w = GridSearchCV(estimator = rfc_w, param_grid = parameters_forest, cv=5, scoring='f1', n_jobs = -1)\n",
    "rfc_gs_w.fit(features_train, target_train)\n",
    "rfc_gs_w.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 мера лучшей модели случайного леса: 0.6314606741573033\n",
      "AUC-ROC метрика: 0.8543830412717232\n"
     ]
    }
   ],
   "source": [
    "rfc_w = rfc_gs_w.best_estimator_\n",
    "rfc_w.fit(features_train, target_train)\n",
    "\n",
    "predictions_valid = rfc_w.predict(features_valid)\n",
    "predicted_proba_valid = rfc_w.predict_proba(features_valid)\n",
    "predictions_one_valid = predicted_proba_valid[:, 1]\n",
    "\n",
    "print('F1 мера лучшей модели случайного леса:', f1_score(target_valid, predictions_valid))\n",
    "print('AUC-ROC метрика:', roc_auc_score(target_valid, predictions_one_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 1.25 s\n",
      "Wall time: 6.48 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'max_depth': 6, 'min_samples_leaf': 10, 'min_samples_split': 2}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "dtc_w = DecisionTreeClassifier(random_state=12345, class_weight='balanced')\n",
    "\n",
    "dtc_gs_w = GridSearchCV(estimator = dtc_w, param_grid = parameters_tree, cv=5, scoring='f1', n_jobs = -1)\n",
    "dtc_gs_w.fit(features_train, target_train)\n",
    "dtc_gs_w.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 мера лучшей модели решающего дерева: 0.5748837209302327\n",
      "AUC-ROC метрика: 0.8295961141792535\n"
     ]
    }
   ],
   "source": [
    "dtc_w = dtc_gs_w.best_estimator_\n",
    "dtc_w.fit(features_train, target_train)\n",
    "\n",
    "predictions_valid = dtc_w.predict(features_valid)\n",
    "predicted_proba_valid = dtc_w.predict_proba(features_valid)\n",
    "predictions_one_valid = predicted_proba_valid[:, 1]\n",
    "\n",
    "print('F1 мера лучшей модели решающего дерева:', f1_score(target_valid, predictions_valid))\n",
    "print('AUC-ROC метрика:', roc_auc_score(target_valid, predictions_one_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(class_weight='balanced', penalty='l1', random_state=12345,\n",
       "                   solver='liblinear')"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_lr_w = LogisticRegression(random_state=12345, solver='liblinear', penalty='l1', class_weight='balanced')\n",
    "model_lr_w.fit(features_train, target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 мера лучшей модели логистической регрессии: 0.48835202761000857\n",
      "AUC-ROC метрика: 0.7643752381758903\n"
     ]
    }
   ],
   "source": [
    "predictions_valid = model_lr_w.predict(features_valid)\n",
    "predicted_proba_valid = model_lr_w.predict_proba(features_valid)\n",
    "predictions_one_valid = predicted_proba_valid[:, 1]\n",
    "\n",
    "print('F1 мера лучшей модели логистической регрессии:', f1_score(target_valid, predictions_valid))\n",
    "print('AUC-ROC метрика:', roc_auc_score(target_valid, predictions_one_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вывод"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Итак, третий способ показал хорошие итоговые результаты проверки с помощью метрик качества. Результаты для случайного леса незначительно, но выросли, дерево решений также показало хороший результат (хотя и ниже чем при использовании downsampling), логистическая регрессия показала такие же результаты как и при предыдущих способах.\n",
    "\n",
    "Случайный лес:\n",
    "- F1 = 0.631\n",
    "- AUC-ROC = 0.854\n",
    "\n",
    "Решающее дерево:\n",
    "- F1 = 0.574\n",
    "- AUC-ROC = 0.829\n",
    "\n",
    "Логистическая регрессия: \n",
    "- F1 = 0.488\n",
    "- AUC-ROC = 0.764\n",
    "\n",
    "Таким образом, лучшая модель - случайный лес с гиперпараметром *class_weight='balanced'*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Тестирование модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Так как мы уже проверили модель на валидационной выборке, то можно включить ее в обучающую, чтобы повысить качество обучения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(class_weight='balanced', max_depth=10,\n",
       "                       min_samples_leaf=2, min_samples_split=6, n_estimators=71,\n",
       "                       random_state=12345)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc_best = rfc_gs_w.best_estimator_\n",
    "rfc_best.fit(pd.concat([features_train, features_valid]), pd.concat([target_train, target_valid]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 мера лучшей модели случайного леса: 0.6162528216704289\n",
      "AUC-ROC метрика: 0.8530546223715317\n"
     ]
    }
   ],
   "source": [
    "predictions_test = rfc_best.predict(features_test)\n",
    "predicted_proba_test = rfc_best.predict_proba(features_test)\n",
    "predicted_one_test = predicted_proba_test[:, 1]\n",
    "\n",
    "print('F1 мера лучшей модели случайного леса:', f1_score(target_test, predictions_test))\n",
    "print('AUC-ROC метрика:', roc_auc_score(target_test, predicted_one_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Протестировали полученную модель на тестовой выборке, получили более высокие результаты метрик F1 и AUC-ROC. \n",
    "\n",
    "Результаты лучшей модели:\n",
    "- F1 = 0.616\n",
    "- AUC-ROC = 0.853\n",
    "\n",
    "Порог пройден, модель прошла проверку."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Общий вывод"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Итак, в данном проекте был проанализирован датасет с данными о клиентах банка, и на основании этих данных исследована задача прогнозирования того, уйдет ли клиент из этого банка или останется.\n",
    "\n",
    "\n",
    "**1. Подготовка данных**\n",
    "\n",
    "В начале работы данные необходимо подготовить, исходный датасет нуждается в преобразованиях для решения нашей задачи. Данные были загружены, создан датафрейм, изучен. Дальнейшие шаги подготовки данных:\n",
    "\n",
    "- Обработаны пропуски в столбце tenure, заполнены медианным значением\n",
    "- Удален столбце surname, так как он не нужен для решения поставленной задачи\n",
    "- Категориальные признаки превращены в численные с помощью прямого кодирования OHE\n",
    "- Датасет разделен на обучающую, валидационную и тестовую выборки\n",
    "- Столбцы с количественными признаками масштабированы, чтобы избежать того, что модель выделит какие-то признаки как более важные\n",
    "\n",
    "**2. Исследование моделей с дисбалансом.**\n",
    "\n",
    "Как выяснилось, в данных присутствовал сильный дисбаланс классов. Для качественного обучения моделей классы должны быть в соотношении примерно 1:1, в наших же данных соотношение было примерно 4:1. \n",
    "\n",
    "Для начала при обучении моделей использовался датасет без учета дисбаланса классов. Для подбора лучших параметров использовался алгоритм GridSearch. Получившаяся модель с этими параметрами обучалась и давала предсказания, которые сравнивались с действительными значениями целевого признака с помощью метрики F1 (метрика качества классификации, являющаяся средним гармоническим полноты и точности). \n",
    "\n",
    "Также исследовали модели с помощью метрики AUC-ROC - метрика качества классификации, равная площади под ROC-кривой (график зависимости доли истинно положительных ответов от доли ложноположительных ответов) (значения метрики изменяются от 0 до 1, AUC-ROC случайной модели равна 0.5).\n",
    "\n",
    "Итоги исследования:\n",
    "\n",
    "Случайный лес:\n",
    "- F1 = 0.565\n",
    "- AUC-ROC = 0.843\n",
    "\n",
    "Решающее дерево:\n",
    "- F1 = 0.546\n",
    "- AUC-ROC = 0.821\n",
    "\n",
    "Логистическая регрессия: \n",
    "- F1 = 0.33\n",
    "- AUC-ROC = 0.758\n",
    "\n",
    "Нужно было получить результат F1 по крайней мере 0.59, без решения проблемы дисбаланса этого не достичь. \n",
    "\n",
    "**3. Борьба с дисбалансом.**\n",
    "\n",
    "Чтобы добиться желаемого качества моделей необходимо разобраться с дисбалансом. Для этого есть несколько способов:\n",
    "\n",
    "**3.1. Upsampling**\n",
    "\n",
    "Первой рассмотрим upsampling - техника балансирования классов, которая заключается в увеличении числа объектов меньшего класса путём их многократного копирования (в данном случае в 4 раза). После преобразования обучающей выборки получили соотношение классов примерно 1:1, после чего обучили на новой выборке модели.\n",
    "\n",
    "Также для подбора лучших параметров для обучения на новой выборке используем GridSearch.\n",
    "\n",
    "Результаты тестов F1 и AUC-ROC для случайного леса и логистической регрессии выросли, ведь мы увеличили размер обучающей выборки. Также мы избавились от дисбаланса классов, что, конечно же, тоже повышает качество обучения. Но в данном случае не для дерева решений, оно показало результаты даже меньше чем с дибалансом. Возможно, модель переобучилась, что привело к падению качества.\n",
    "\n",
    "Результаты после обучения на преобразованной с помощью upsampling выборке:\n",
    "\n",
    "Случайный лес:\n",
    "- F1 = 0.624\n",
    "- AUC-ROC = 0.851\n",
    "\n",
    "Решающее дерево:\n",
    "- F1 = 0.506\n",
    "- AUC-ROC = 0.712\n",
    "\n",
    "Логистическая регрессия: \n",
    "- F1 = 0.488\n",
    "- AUC-ROC = 0.764\n",
    "\n",
    "**3.2. Downsampling**\n",
    "\n",
    "Downsampling - техника балансирования классов, которая заключается в уменьшении числа объектов большего класса путём случайного удаления объектов большего класса (в данном случае уменьшили в 4 раза).\n",
    "\n",
    "Результат для случайного леса получился ниже чем при использовании предыдущего способа. Это объясняется тем, что метод downsampling уменьшает обучающую выборку, что приводит к уменьшению качества обучения в данном случае, так как исследуемый датасет, а следовательно и обучающая выборка, изначально по объему не слишком большие. Но для алгоритма дерева решений заметен значительный прирост качества, так как мы избавились от дисбаланса, а модель в данном случае не переобучилась (по крайней мере не так сильно). Результаты для логистической регрессии почти не изменились.\n",
    "\n",
    "Результаты после обучения на преобразованной с помощью downsampling выборке:\n",
    "\n",
    "Случайный лес:\n",
    "- F1 = 0.597\n",
    "- AUC-ROC = 0.850\n",
    "\n",
    "Решающее дерево:\n",
    "- F1 = 0.578\n",
    "- AUC-ROC = 0.830\n",
    "\n",
    "Логистическая регрессия: \n",
    "- F1 = 0.487\n",
    "- AUC-ROC = 0.763\n",
    "\n",
    "**3.3. Взвешивание классов**\n",
    "\n",
    "Третий способ борьбы с дисбалансом - изменение гиперпараметра *class_weight='balanced*, показал хорошие итоговые результаты проверки с помощью метрик качества. Результаты для случайного леса незначительно, но выросли, дерево решений также показало хороший результат (хотя и ниже чем при использовании downsampling), логистическая регрессия показала такие же результаты как и при предыдущих способах.\n",
    "\n",
    "Случайный лес:\n",
    "- F1 = 0.631\n",
    "- AUC-ROC = 0.854\n",
    "\n",
    "Решающее дерево:\n",
    "- F1 = 0.574\n",
    "- AUC-ROC = 0.829\n",
    "\n",
    "Логистическая регрессия: \n",
    "- F1 = 0.488\n",
    "- AUC-ROC = 0.764\n",
    "\n",
    "Таким образом, лучшая модель - случайный лес с измененными весами классов (гиперпараметром *class_weight='balanced'*).\n",
    "\n",
    "**4. Тестирование лучшей модели.**\n",
    "\n",
    "Сначала заново обучили нашу лучшую модель на обучающей+валидационной выборке, после чего протестировали на тестовой выборке. В итоге модель показала более высокие результаты.\n",
    "\n",
    "Результаты лучшей модели:\n",
    "\n",
    "- F1 = 0.616\n",
    "- AUC-ROC = 0.853"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Содержание",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
